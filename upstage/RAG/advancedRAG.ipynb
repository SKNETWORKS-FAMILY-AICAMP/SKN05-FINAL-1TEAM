{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kiwipiepy\n",
    "# !pip install --upgrade cohere\n",
    "# !pip install cohere openai langchain pinecone-client\n",
    "# !pip install dill\n",
    "# !pip install rank-bm25\n",
    "# !pip install rank-bm25 nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bm25_retriever_ooo.pkl 파일 만드는 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m tokenized_corpus \u001b[38;5;241m=\u001b[39m [word_tokenize(doc\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 🔹 BM25 모델 학습\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m bm25 \u001b[38;5;241m=\u001b[39m \u001b[43mBM25Okapi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_corpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 🔹 BM25 모델 및 문서 ID 저장\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(bm25_pkl_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pkl_file:\n",
      "File \u001b[1;32mc:\\Users\\USER\\miniconda3\\envs\\20240909\\Lib\\site-packages\\rank_bm25.py:83\u001b[0m, in \u001b[0;36mBM25Okapi.__init__\u001b[1;34m(self, corpus, tokenizer, k1, b, epsilon)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m=\u001b[39m b\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m=\u001b[39m epsilon\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\miniconda3\\envs\\20240909\\Lib\\site-packages\\rank_bm25.py:27\u001b[0m, in \u001b[0;36mBM25.__init__\u001b[1;34m(self, corpus, tokenizer)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer:\n\u001b[0;32m     25\u001b[0m     corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenize_corpus(corpus)\n\u001b[1;32m---> 27\u001b[0m nd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_idf(nd)\n",
      "File \u001b[1;32mc:\\Users\\USER\\miniconda3\\envs\\20240909\\Lib\\site-packages\\rank_bm25.py:52\u001b[0m, in \u001b[0;36mBM25._initialize\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m     48\u001b[0m             nd[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgdl \u001b[38;5;241m=\u001b[39m \u001b[43mnum_doc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_size\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nd\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# NLTK tokenizer를 사용하기 위한 다운로드 (최초 1회 필요)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 🔹 JSON 파일 경로\n",
    "json_file_path = \"../parse/sony_zv-1_list.json\"\n",
    "bm25_pkl_file_path = \"../data/bm25_retrieve_zv-1.pkl\"\n",
    "\n",
    "# 🔹 JSON 파일 로드\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# 🔹 BM25 인덱스를 위한 문서 리스트 및 ID 저장\n",
    "documents = []\n",
    "document_ids = []\n",
    "\n",
    "for page in data:\n",
    "    page_number = page.get(\"page\", \"unknown\")\n",
    "    for item in page.get(\"items\", []):\n",
    "        if \"md\" in item:  # Markdown 텍스트 추출\n",
    "            text_content = item[\"md\"]\n",
    "            documents.append(text_content)\n",
    "            document_ids.append(f\"page-{page_number}-{item.get('value', 'unknown')}\")\n",
    "\n",
    "# 🔹 문서 토큰화\n",
    "tokenized_corpus = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "# 🔹 BM25 모델 학습\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# 🔹 BM25 모델 및 문서 ID 저장\n",
    "with open(bm25_pkl_file_path, \"wb\") as pkl_file:\n",
    "    pickle.dump((bm25, document_ids, documents), pkl_file)\n",
    "\n",
    "print(f\"✅ BM25 모델이 포함된 `bm25_retrieve_zv-1.pkl` 파일 생성 완료: {bm25_pkl_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# NLTK 토크나이저 다운로드 (최초 실행 시 필요)\n",
    "nltk.download('punkt')\n",
    "\n",
    "class BM25Retriever:\n",
    "    def __init__(self, json_path=None, pkl_path=None):\n",
    "        \"\"\"\n",
    "        JSON 파일에서 데이터를 로드하여 BM25 모델을 생성하거나,\n",
    "        기존 BM25 모델을 pkl 파일에서 로드하여 사용.\n",
    "        \"\"\"\n",
    "        if pkl_path:\n",
    "            self.load_from_pkl(pkl_path)\n",
    "        elif json_path:\n",
    "            self.load_from_json(json_path)\n",
    "        else:\n",
    "            raise ValueError(\"JSON 또는 PKL 파일 경로를 제공해야 합니다.\")\n",
    "\n",
    "    def load_from_json(self, json_path):\n",
    "        \"\"\"JSON 파일에서 데이터를 로드하여 BM25 모델을 생성\"\"\"\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        self.documents = []\n",
    "        self.document_ids = []\n",
    "        \n",
    "        for page in data:\n",
    "            page_number = page.get(\"page\", \"unknown\")\n",
    "            for item in page.get(\"items\", []):\n",
    "                if \"md\" in item:\n",
    "                    text_content = item[\"md\"]\n",
    "                    self.documents.append(text_content)\n",
    "                    self.document_ids.append(f\"page-{page_number}-{item.get('value', 'unknown')}\")\n",
    "\n",
    "        self.tokenized_corpus = [word_tokenize(doc.lower()) for doc in self.documents]\n",
    "        self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "\n",
    "    def save_to_pkl(self, pkl_path):\n",
    "        \"\"\"BM25 모델을 pkl 파일로 저장\"\"\"\n",
    "        with open(pkl_path, \"wb\") as pkl_file:\n",
    "            pickle.dump((self.bm25, self.document_ids, self.documents), pkl_file)\n",
    "        print(f\"✅ BM25 모델이 `{pkl_path}`에 저장되었습니다.\")\n",
    "\n",
    "    def load_from_pkl(self, pkl_path):\n",
    "        \"\"\"BM25 모델을 pkl 파일에서 로드\"\"\"\n",
    "        with open(pkl_path, \"rb\") as pkl_file:\n",
    "            self.bm25, self.document_ids, self.documents = pickle.load(pkl_file)\n",
    "\n",
    "    def retrieve(self, query, top_n=5):\n",
    "        \"\"\"주어진 쿼리에 대해 BM25 검색 수행\"\"\"\n",
    "        tokenized_query = word_tokenize(query.lower())\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "\n",
    "        # 상위 n개 검색 결과 가져오기\n",
    "        top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "\n",
    "        results = []\n",
    "        for idx in top_indexes:\n",
    "            results.append({\n",
    "                \"document_id\": self.document_ids[idx],\n",
    "                \"text\": self.documents[idx],\n",
    "                \"score\": scores[idx]\n",
    "            })\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"../parse/sony_zv-1_list.json\"\n",
    "bm25_pkl_path = \"../data/bm25_retrieve_zv-1.pkl\"\n",
    "\n",
    "# BM25 모델 생성 및 저장\n",
    "retriever = BM25Retriever(json_path=json_path)\n",
    "retriever.save_to_pkl(bm25_pkl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# NLTK tokenizer를 사용하기 위한 다운로드 (최초 1회 필요)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_file_path = \"../parse/sony_zv-1_list.json\"\n",
    "bm25_pkl_file_path = \"../data/bm25_retrieve_zv-1.pkl\"\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# 문서 리스트 생성 (BM25 입력용)\n",
    "documents = []\n",
    "document_ids = []\n",
    "\n",
    "for page in data:\n",
    "    page_number = page.get(\"page\", \"unknown\")\n",
    "    for item in page.get(\"items\", []):\n",
    "        if \"md\" in item:\n",
    "            text_content = item[\"md\"]\n",
    "            documents.append(text_content)\n",
    "            document_ids.append(f\"page-{page_number}-{item.get('value', 'unknown')}\")\n",
    "\n",
    "# 문서 토큰화\n",
    "tokenized_corpus = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "# BM25 모델 학습\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# BM25 모델과 문서 ID를 pkl 파일로 저장\n",
    "with open(bm25_pkl_file_path, \"wb\") as pkl_file:\n",
    "    pickle.dump((bm25, document_ids, documents), pkl_file)\n",
    "\n",
    "print(f\"✅ BM25 모델이 포함된 `bm25_retrieve_zv-1.pkl` 파일 생성 완료: {bm25_pkl_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .pkl파일 만드는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON 데이터를 PKL 파일로 저장 완료: ../data/zv-1.pkl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_file_path = \"../parse/sony_zv-1_list.json\"\n",
    "pkl_file_path = \"../data/zv-1.pkl\"\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as json_file: \n",
    "    data = json.load(json_file)\n",
    "\n",
    "# PKL 파일로 저장\n",
    "with open(pkl_file_path, \"wb\") as pkl_file:\n",
    "    pickle.dump(data, pkl_file)\n",
    "\n",
    "print(f\"✅ JSON 데이터를 PKL 파일로 저장 완료: {pkl_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from kiwipiepy import Kiwi\n",
    "import dill\n",
    "\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def kiwi_tokenize(text):\n",
    "    return [token.form for token in kiwi.tokenize(text)]\n",
    "\n",
    "with open(\"../parse/sony_zv-1_list.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "documents = []\n",
    "for item in json_data:\n",
    "    text = item[\"text_field\"]  # \"text_field\"는 텍스트 데이터를 포함하는 필드 이름\n",
    "    documents.append(text)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_texts(documents, preprocess_func=kiwi_tokenize)\n",
    "\n",
    "with open(\"../data/bm25_retriever_a6400.pkl\", \"wb\") as f:\n",
    "    dill.dump(bm25_retriever, f)\n",
    "\n",
    "print(\"bm25_retriever_a6400.pkl 파일 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG 찐 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bm25 pkl 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m document_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m---> 24\u001b[0m     page_number \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m page\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m\"\u001b[39m, []):\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmd\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m item \u001b[38;5;129;01mand\u001b[39;00m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmd\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip():  \u001b[38;5;66;03m# 빈 문서 필터링\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import dill  # dill은 pickle보다 확장된 직렬화 지원\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# NLTK 토크나이저 사용을 위한 다운로드 (최초 1회 필요)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 🔹 JSON 파일 경로\n",
    "json_file_path = \"../parse/sony_zv-1_list.json\"\n",
    "bm25_pkl_file_path = \"../data/retriever_zv-1.pkl\"\n",
    "\n",
    "# 🔹 JSON 파일 로드\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# 🔹 BM25 학습용 문서 리스트 및 ID 저장\n",
    "documents = []\n",
    "document_ids = []\n",
    "\n",
    "for page in data:\n",
    "    page_number = page.get(\"page\", \"unknown\")\n",
    "    for item in page.get(\"items\", []):\n",
    "        if \"md\" in item and item[\"md\"].strip():  # 빈 문서 필터링\n",
    "            text_content = item[\"md\"]\n",
    "            documents.append(text_content)\n",
    "            document_ids.append(f\"page-{page_number}-{item.get('value', 'unknown')}\")\n",
    "\n",
    "# 🔹 문서 토큰화 (BM25 입력용)\n",
    "tokenized_corpus = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "# 🔹 BM25 모델 학습\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# 🔹 BM25 Retriever 데이터 저장\n",
    "bm25_retriever = {\n",
    "    \"bm25\": bm25,\n",
    "    \"document_ids\": document_ids,\n",
    "    \"documents\": documents\n",
    "}\n",
    "\n",
    "with open(bm25_pkl_file_path, \"wb\") as pkl_file:\n",
    "    dill.dump(bm25_retriever, pkl_file)\n",
    "\n",
    "print(f\"✅ BM25 Retriever 모델이 `{bm25_pkl_file_path}` 파일로 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading BM25 retriever: 'list' object has no attribute 'preprocess_func'\n",
      "Warning: BM25 검색기를 사용할 수 없어, 벡터 검색기만 사용합니다.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings  # Correct importo\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from kiwipiepy import Kiwi\n",
    "from pinecone import Pinecone\n",
    "import cohere\n",
    "import dill  # dill import 추가\n",
    "\n",
    "load_dotenv(override=True)  # 강제 다시 로드\n",
    "\n",
    "# API 키 확인 및 설정 (기존 코드 유지)\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "if not os.environ.get(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter Pinecone API key: \")\n",
    "\n",
    "pinecone_api = os.environ[\"PINECONE_API_KEY\"]\n",
    "cohere_api = os.environ.get(\"COHERE_API_KEY\")  # .get()을 사용하여 키가 없을 때 None 반환\n",
    "\n",
    "if not cohere_api:\n",
    "    raise ValueError(\"COHERE_API_KEY 환경 변수를 설정해주세요.\")\n",
    "\n",
    "\n",
    "# 벡터 스토어 로드 (기존 코드 유지)\n",
    "pc = Pinecone(api_key=pinecone_api)\n",
    "index_name = \"sony\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # Corrected model name\n",
    "\n",
    "vector_store = PineconeVectorStore(embedding=embeddings, index=index)\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 10},\n",
    ")\n",
    "\n",
    "# Kiwi 토크나이저 (기존 코드 유지)\n",
    "kiwi = Kiwi()\n",
    "def kiwi_tokenize(text):\n",
    "    return [token.form for token in kiwi.tokenize(text)]\n",
    "\n",
    "# BM25 검색기 로드 (수정: 파일에서 로드)\n",
    "try:\n",
    "    with open(\"../data/zv-1.pkl\", \"rb\") as f:\n",
    "        bm25_retriever = dill.load(f)\n",
    "    bm25_retriever.preprocess_func = kiwi_tokenize\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: zv-1.pkl 파일을 찾을 수 없습니다. BM25 검색을 사용할 수 없습니다.\")\n",
    "    bm25_retriever = None  # BM25 검색기 사용 안함\n",
    "except Exception as e:  # 다른 예외 처리\n",
    "    print(f\"Error loading BM25 retriever: {e}\")\n",
    "    bm25_retriever = None \n",
    "\n",
    "# 앙상블 검색기 생성 (수정: BM25 검색기 존재 여부 확인)\n",
    "if bm25_retriever:  # BM25 검색기가 로드된 경우에만 앙상블 검색기 생성\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[retriever, bm25_retriever],\n",
    "        weights=[0.5, 0.5]  # Dense와 BM25 각각 50% 가중치\n",
    "    )\n",
    "else:\n",
    "    ensemble_retriever = retriever  # BM25 검색기 없을 경우 벡터 검색기만 사용\n",
    "    print(\"Warning: BM25 검색기를 사용할 수 없어, 벡터 검색기만 사용합니다.\")\n",
    "\n",
    "\n",
    "cohere_client = cohere.Client(cohere_api)  # 기존 코드 유지\n",
    "\n",
    "# ... (이후 검색 및 처리 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.retrievers import BM25Retriever,EnsembleRetriever\n",
    "from kiwipiepy import Kiwi\n",
    "import cohere\n",
    "# import dill\n",
    "\n",
    "load_dotenv(override=True) # 강제 다시 로드\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "if not os.environ.get(\"PINECONE_API_KEY\"):\n",
    "  os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter Pinecone API key: \")\n",
    "\n",
    "pinecone_api = os.environ[\"PINECONE_API_KEY\"]\n",
    "cohere_api = os.environ[\"COHERE_API_KEY\"]\n",
    "\n",
    "# vectorstore load\n",
    "# 문서 검색 (Hybrid Search: BM25 + Pinecone)\n",
    "# pinecone 벡터 기반 검색\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api)\n",
    "\n",
    "index_name = \"sony\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vector_store = PineconeVectorStore(embedding=embeddings, index=index)\n",
    "\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "  search_type=\"similarity\", search_kwargs={\"k\": 10},\n",
    ")\n",
    "\n",
    "# BM25 키워드 기반 검색 \n",
    "# ✅ BM25Retriever를 사용하여 키워드 기반 검색 수행\n",
    "# ✅ 한국어 형태소 분석기 kiwipiepy를 사용하여 검색 성능 최적화\n",
    "# ✅ BM25 모델을 .pkl 파일로 저장하여 로드 가능 -> drill로 로드\n",
    "kiwi = Kiwi()\n",
    "def kiwi_tokenize(text):\n",
    "    return [token.form for token in kiwi.tokenize(text)]\n",
    "\n",
    "\n",
    "\n",
    "# === 1. BM25Retriever와 Kiwi 로드 ===\n",
    "with open(\"../data/zv-1.pkl\", \"rb\") as f:\n",
    "    bm25_retriever = dill.load(f)\n",
    "\n",
    "\n",
    "bm25_retriever.preprocess_func = kiwi_tokenize\n",
    "\n",
    "# === 3. Ensemble Retriever 생성 ===\n",
    "# BM25 + Pinecone 결합 (Ensemble Search)\n",
    "# 두 가지 검색 방식을 결합하여 검색 성능 향상 (하이브리드 검색)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[retriever, bm25_retriever],\n",
    "    weights=[0.5, 0.5]  # Dense와 BM25 각각 50% 가중치\n",
    ")\n",
    "\n",
    "cohere_client = cohere.Client(cohere_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #✅ 사용자의 질문과 검색 & 응답 상태를 저장하는 역할\n",
    "# #✅ 각 단계에서 필요한 데이터를 유지하며 전달됨\n",
    "# # state 코드 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List\n",
    "\n",
    "# 1. 질문 관련 State\n",
    "class QuestionState(TypedDict):\n",
    "    question: Annotated[str, \"Question\"]\n",
    "    transform_question: Annotated[List[str], \"Transformed queries generated by LLM\"]  # List로 변경\n",
    "\n",
    "# 2. 검색 및 컨텍스트 관련 State\n",
    "class ContextRetrievalState(TypedDict):\n",
    "    ensemble_context: Annotated[str, \"Ensemble Retrieve\"]\n",
    "    multi_context: Annotated[str, \"Multi Query\"]\n",
    "    merge_context: Annotated[str, \"Merge Context\"]\n",
    "    filtered_context: Annotated[str, \"Filtering Context\"]\n",
    "    rerank_context: Annotated[str, \"Reranked Context\"]  # reranked context 혹은 context로 표기하기\n",
    "\n",
    "# 3. 답변 및 메시지 관련 State\n",
    "class AnswerState(TypedDict):\n",
    "    answer: Annotated[str, \"Answer\"]\n",
    "    message: Annotated[List[dict], \"Messages\"] # add_messages type hint 제거. List[dict]로 명시\n",
    "\n",
    "\n",
    "# 4. 전체 Graph State (각 부분 State를 포함)\n",
    "class GraphState(TypedDict): \n",
    "    question_state: QuestionState\n",
    "    context_retrieval_state: ContextRetrievalState\n",
    "    answer_state: AnswerState\n",
    "\n",
    "\n",
    "# # 사용 예시:\n",
    "# initial_state: GraphState = {\n",
    "#     \"question_state\": {\n",
    "#         \"question\": \"What is the capital of France?\",\n",
    "#         \"transform_question\": []  # 초기 빈 리스트\n",
    "#     },\n",
    "#     \"context_retrieval_state\": {\n",
    "#         \"ensemble_context\": \"\",\n",
    "#         \"multi_context\": \"\",\n",
    "#         \"merge_context\": \"\",\n",
    "#         \"filtered_context\": \"\",\n",
    "#         \"rerank_context\": \"\"\n",
    "#     },\n",
    "#     \"answer_state\": {\n",
    "#         \"answer\": \"\",\n",
    "#         \"message\": [] # 초기 빈 리스트\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "# # 상태 업데이트 예시:\n",
    "# updated_state: GraphState = initial_state.copy() # 중요: copy()를 사용하여 원본 상태를 변경하지 않도록 함\n",
    "# updated_state[\"question_state\"][\"transform_question\"].append(\"What is the capital of France?\")\n",
    "# updated_state[\"context_retrieval_state\"][\"ensemble_context\"] = \"Paris is the capital...\"\n",
    "# updated_state[\"answer_state\"][\"answer\"] = \"Paris\"\n",
    "# updated_state[\"answer_state\"][\"message\"].append({\"role\": \"assistant\", \"content\": \"Paris is the capital of France.\"})\n",
    "\n",
    "# print(updated_state)\n",
    "\n",
    "\n",
    "# # add_message 함수를 사용하는 예시 (별도 함수로 정의)\n",
    "# def add_message(state: GraphState, role: str, content: str):\n",
    "#     new_message = {\"role\": role, \"content\": content}\n",
    "#     updated_state = state.copy()\n",
    "#     updated_state[\"answer_state\"][\"message\"].append(new_message)\n",
    "#     return updated_state\n",
    "\n",
    "# updated_state = add_message(updated_state, \"user\", \"Thank you!\")\n",
    "# print(updated_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List\n",
    "import retriever\n",
    "import ensemble_retriever\n",
    "import bm25_retriever\n",
    "\n",
    "# 🔹 질문 관련 State\n",
    "class QuestionState(TypedDict):\n",
    "    question: Annotated[str, \"Original question from user\"]\n",
    "    transform_question: Annotated[List[str], \"Transformed queries generated by LLM\"]  # List 타입 유지\n",
    "\n",
    "# 🔹 검색 및 컨텍스트 관련 State\n",
    "class ContextRetrievalState(TypedDict):\n",
    "    ensemble_context: Annotated[str, \"Ensemble Retrieved Context\"]\n",
    "    multi_context: Annotated[str, \"Multi Query Retrieved Context\"]\n",
    "    merge_context: Annotated[str, \"Merged Context\"]\n",
    "    filtered_context: Annotated[str, \"Filtered Context\"]\n",
    "    rerank_context: Annotated[str, \"Reranked Context\"]  # 표준화된 key 이름 유지\n",
    "\n",
    "# 🔹 답변 및 메시지 관련 State\n",
    "class AnswerState(TypedDict):\n",
    "    answer: Annotated[str, \"Final Answer\"]\n",
    "    message: Annotated[List[dict], \"Message history\"]  # List[dict]로 변경\n",
    "\n",
    "# 🔹 전체 Graph State (각 State 포함)\n",
    "class GraphState(TypedDict):\n",
    "    question_state: QuestionState\n",
    "    context_retrieval_state: ContextRetrievalState\n",
    "    answer_state: AnswerState\n",
    "\n",
    "\n",
    "# 🔹 **기본 Retriever를 이용하여 문서 검색**\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    기본 Retriever를 사용하여 질문에 대한 문서를 검색합니다.\n",
    "    \"\"\"\n",
    "    question = state[\"question_state\"][\"question\"]  # 질문 가져오기\n",
    "    documents = retriever.invoke(question)  # 기본 retriever 호출\n",
    "    print(f\"🔎 Retrieved documents: {documents}\")\n",
    "\n",
    "    # 업데이트된 State 반환\n",
    "    state[\"context_retrieval_state\"][\"multi_context\"] = documents  # multi_query에서 가져온 컨텍스트\n",
    "    return state\n",
    "\n",
    "\n",
    "# 🔹 **Ensemble Retriever를 이용한 검색**\n",
    "def ensemble_document(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Ensemble Retriever를 사용하여 질문에 대한 문서를 검색합니다.\n",
    "    \"\"\"\n",
    "    question = state[\"question_state\"][\"question\"]  # 질문 가져오기\n",
    "    documents = ensemble_retriever.invoke(question)  # Ensemble retriever 호출\n",
    "    print(f\"🔎 Ensemble Retrieved documents: {documents}\")\n",
    "\n",
    "    # 업데이트된 State 반환\n",
    "    state[\"context_retrieval_state\"][\"ensemble_context\"] = documents  # Ensemble retrieval 적용 결과 저장\n",
    "    return state\n",
    "\n",
    "\n",
    "# 🔹 **BM25 Retriever를 이용한 검색 (옵션)**\n",
    "def bm25_document(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    BM25 기반 검색을 수행합니다.\n",
    "    \"\"\"\n",
    "    question = state[\"question_state\"][\"question\"]  # 질문 가져오기\n",
    "    if bm25_retriever:\n",
    "        documents = bm25_retriever.invoke(question)  # BM25 retriever 호출\n",
    "        print(f\"🔎 BM25 Retrieved documents: {documents}\")\n",
    "\n",
    "        # 업데이트된 State 반환\n",
    "        state[\"context_retrieval_state\"][\"filtered_context\"] = documents  # BM25 기반 컨텍스트 저장\n",
    "    else:\n",
    "        print(\"⚠️ BM25 Retriever가 존재하지 않습니다. 기본 검색만 수행됩니다.\")\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ContextRetrievalState\n",
    "# import retriever, ensemble_retriever, bm25_retriever\n",
    "\n",
    "# def retrieve_document(state: GraphState) -> GraphState:\n",
    "#     questions = state[\"question\"]\n",
    "#     documents = retriever.invoke(questions)\n",
    "#     print(documents)\n",
    "#     return {\"context\": documents, \"question\": questions}\n",
    "\n",
    "# # Ensemble retriever 정의\n",
    "# def ensemble_document(state: GraphState) -> GraphState:\n",
    "#     questions = state[\"question\"]\n",
    "#     documents = ensemble_retriever.invoke(questions)\n",
    "#     # print(documents)\n",
    "#     return {\"ensemble_context\": documents}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# 환경 변수 로드 (API 키를 .env 파일에 저장하고 로드합니다.)\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 키 확인 및 설정\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY 환경 변수를 설정해주세요.\")\n",
    "\n",
    "# OpenAI Embeddings 초기화 (API 키 포함)\n",
    "embed_model = OpenAIEmbeddings(openai_api_key=openai_api_key, model=\"text-embedding-ada-002\") # 모델 지정 (선택적)\n",
    "\n",
    "# Pinecone 벡터 스토어 초기화 (index 객체가 미리 정의되어 있어야 합니다.)\n",
    "pinecone_retriever = Pinecone(index, embed_model)\n",
    "\n",
    "# BM25 키워드 검색기 초기화 (documents 리스트가 미리 정의되어 있어야 합니다.)\n",
    "bm25_retriever = BM25Retriever.from_texts(documents)\n",
    "\n",
    "# Hybrid 검색 (BM25 + Pinecone)\n",
    "query = \"Sony 카메라의 크기\"\n",
    "bm25_results = bm25_retriever.get_relevant_documents(query)\n",
    "pinecone_results = pinecone_retriever.similarity_search(query, top_k=5)\n",
    "\n",
    "# 두 결과를 결합하여 Hybrid 검색 결과 생성 (중복 제거)\n",
    "combined_results = list(set(bm25_results + pinecone_results))  # 중복 제거 및 리스트로 변환\n",
    "\n",
    "# 출력\n",
    "print(\" Hybrid 검색 결과:\") \n",
    "for doc in combined_results:\n",
    "    print(f\"- {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.retrievers import BM25Retriever\n",
    "# from langchain.vectorstores import BM25Retriever\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 Pinecone 벡터 스토어 초기화\n",
    "pinecone_retriever = Pinecone(index, embed_model)\n",
    "\n",
    "# 🔹 BM25 키워드 검색기 초기화\n",
    "bm25_retriever = BM25Retriever.from_texts(documents)\n",
    "\n",
    "# 🔹 Hybrid 검색 (BM25 + Pinecone)\n",
    "query = \"Sony 카메라의 크기\"\n",
    "bm25_results = bm25_retriever.get_relevant_documents(query)\n",
    "pinecone_results = pinecone_retriever.similarity_search(query, top_k=5)\n",
    "\n",
    "# 🔹 두 결과를 결합하여 Hybrid 검색 결과 생성\n",
    "combined_results = bm25_results + pinecone_results\n",
    "\n",
    "# 🔹 출력\n",
    "print(\"🔍 Hybrid 검색 결과:\")\n",
    "for doc in combined_results:\n",
    "    print(f\"- {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cohere reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from state import GraphState\n",
    "# from ingestion import cohere_client\n",
    "\n",
    "\n",
    "def rerank_with_cohere(query, retrieved_docs, top_n=5):\n",
    "    # Cohere에 전달할 문서 형식\n",
    "    documents = [doc.page_content for doc in retrieved_docs]\n",
    "    \n",
    "    # Reranker 호출a\n",
    "    \n",
    "    response = cohere_client.rerank(\n",
    "        query=query,\n",
    "        documents=documents,\n",
    "        top_n=top_n,  # 상위 N개 문서 선택\n",
    "        model=\"rerank-v3.5\"  # 사용할 Cohere Reranker 모델\n",
    "    )\n",
    "    \n",
    "    # 상위 문서만 반환\n",
    "    reranked_docs = [retrieved_docs[result.index] for result in response.results]\n",
    "    return reranked_docs\n",
    "\n",
    "# Reranker Node\n",
    "def rerank_docs(state: GraphState) -> GraphState:\n",
    "    \n",
    "    questions = state['question']\n",
    "    documents = state['merge_context']\n",
    "    reranked_docs = rerank_with_cohere(questions, documents)\n",
    "    return {\"rerank_context\": reranked_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation.py\n",
    "# 답변 생성 체인\n",
    "from dotenv import load_dotenv\n",
    "# from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "ANSWER_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\",\"context\"],\n",
    "    template=\"\"\"\n",
    "당신은 카메라 사용자 메뉴얼에 대한 정보를 제공하는 AI 어시스턴트입니다. 사용자가 질문을 하면, 제공된 Document 형식의 context를 활용하여 답변을 생성하세요. 각 Document에는 이미지 경로가 포함된 metadata가 있습니다. 답변을 생성할 때, 관련된 이미지가 있는 경우 [image: metadata 내 이미지 경로] 형식으로 답변에 포함시켜 주세요. \n",
    "\n",
    "예시:\n",
    "사용자 질문: \"카메라의 ISO 설정 방법을 알려주세요.\"\n",
    "답변: \"카메라의 ISO 설정은 메뉴에서 '설정'을 선택한 후 'ISO' 옵션을 선택하여 조정할 수 있습니다. [image: /path/to/iso_setting_image]\"\n",
    "\n",
    "이와 같은 형식으로 질문에 대한 답변을 생성하세요.\n",
    "\n",
    "컨텍스트와 질문을 기반으로 답변을 생성하세요:\n",
    "- 컨텍스트: {context}\n",
    "- 질문: {question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "generation_chain = ANSWER_PROMPT | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # 메시지 정의(list type 이며 add_messages 함수를 사용하여 메시지를 추가)\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "\n",
    "# 챗봇 함수 정의\n",
    "def chatbot(state: State):\n",
    "    # 메시지 호출 및 반환\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 노드 이름, 함수 혹은 callable 객체를 인자로 받아 노드를 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 노드에서 챗봇 노드로의 엣지 추가\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 엣지 추가\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"카메라 IOS값 설정법 알려줘줘\"\n",
    "\n",
    "# 그래프 이벤트 스트리밍\n",
    "for event in graph.stream({\"messages\": [(\"user\", question)]}):\n",
    "    # 이벤트 값 출력\n",
    "    for value in event.values():\n",
    "        print(\"Assistant:\", value[\"messages\"][-1].content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20240909",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
