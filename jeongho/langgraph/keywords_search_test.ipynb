{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tavily-python\n",
      "  Downloading tavily_python-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from tavily-python) (2.32.3)\n",
      "Collecting tiktoken>=0.5.1 (from tavily-python)\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: httpx in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from tavily-python) (0.28.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.5.1->tavily-python)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from requests->tavily-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from requests->tavily-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from requests->tavily-python) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from requests->tavily-python) (2024.12.14)\n",
      "Requirement already satisfied: anyio in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from httpx->tavily-python) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from httpx->tavily-python) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /home/jeongho/RAGprojects/RAGprojects_env/lib/python3.12/site-packages (from anyio->httpx->tavily-python) (4.12.2)\n",
      "Downloading tavily_python-0.5.0-py3-none-any.whl (14 kB)\n",
      "Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "Installing collected packages: regex, tiktoken, tavily-python\n",
      "Successfully installed regex-2024.11.6 tavily-python-0.5.0 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ \\'í™”ì´íŠ¸ ë²¨ëŸ°ìŠ¤\\'ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”:\\n\\ní™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤(White Balance)ëŠ” ì‚¬ì§„ì´ë‚˜ ì˜ìƒì—ì„œ ìƒ‰ìƒì„ ì •í™•í•˜ê²Œ í‘œí˜„í•˜ê¸° ìœ„í•´ ì¡°ì •í•˜ëŠ” ê³¼ì •ì´ì—ìš”. ì´ ê¸°ëŠ¥ì€ íŠ¹íˆ ì¡°ëª…ì´ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì´¬ì˜í•  ë•Œ ì¤‘ìš”í•˜ì£ . í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ë¥¼ ì˜ ë§ì¶”ë©´, ì´¬ì˜í•œ ì´ë¯¸ì§€ë‚˜ ì˜ìƒì—ì„œ ìƒ‰ìƒì´ ìì—°ìŠ¤ëŸ½ê³  í˜„ì‹¤ì ìœ¼ë¡œ ë³´ì´ê²Œ\\në””ì§€í„¸ ì‚¬ì§„ì˜ í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì´í•´. í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ëŠ” ìƒ‰ìƒì„ ë³´ë‹¤ ì‚¬ì‹¤ì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ê¸° ìœ„í•œ ë””ì§€í„¸ ì‚¬ì§„ì˜ ì¡°ì • ê¸°ëŠ¥ì…ë‹ˆë‹¤. \"í°ìƒ‰ì„ í°ìƒ‰ìœ¼ë¡œ ë³´ì´ë„ë¡ ë§Œë“¤ê¸° ìœ„í•´ ì‚¬ì§„ì„ ì¤‘ì„±ìƒ‰ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤\"ë¼ê³  ì‚¬ì§„ì‘ê°€ì´ì êµìœ¡ìì¸ Adam Longì€ ë§í•©ë‹ˆë‹¤.\\ní™”ì´íŠ¸ë°¸ëŸ°ìŠ¤ ê¸°ëŠ¥ì€ ì´ ìƒ‰ì˜¨ë„ë¥¼ ì¹´ë©”ë¼ê°€ ê°ì§€í•´ì„œ ì•Œë§ì€ ê°’ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤. í™”ì´íŠ¸ë°¸ëŸ°ìŠ¤ëŠ” ë§ ê·¸ëŒ€ë¡œ í°ìƒ‰ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ ìƒ‰ë“¤ë„ ë³¸ë˜ì˜ ìƒ‰ìœ¼ë¡œ ì°íˆë„ë¡ í•˜ëŠ” ê¸°ëŠ¥ì´ë©°, ì—­ìœ¼ë¡œ ë³¸ë˜ê°€ ì•„ë‹Œ ìƒ‰ìœ¼ë¡œ ì°íˆë„ë¡ í™œìš©í•´ì„œ ê°œì„±\\n\\nì˜¤ì§ ì‚¬ì§„ ì´¬ì˜ê³¼ ì¹´ë©”ë¼ ê¸°ìˆ ê³¼ ê´€ë ¨ëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ìš©ì–´ë¥¼ ì„¤ëª…í•˜ì„¸ìš”. ì¹´ë©”ë¼ì™€ ë¬´ê´€í•œ ì˜ë¯¸(ì˜ˆ: êµ­ì œ í‘œì¤€í™” ê¸°êµ¬)ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"role\": \"user\", \"content\": f\"ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ '{term}'ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”:\\n\\n{search_data}\\n\\n\"\n",
    "                                     f\"ì˜¤ì§ ì‚¬ì§„ ì´¬ì˜ê³¼ ì¹´ë©”ë¼ ê¸°ìˆ ê³¼ ê´€ë ¨ëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ìš©ì–´ë¥¼ ì„¤ëª…í•˜ì„¸ìš”. \"\n",
    "                                     f\"ì¹´ë©”ë¼ì™€ ë¬´ê´€í•œ ì˜ë¯¸(ì˜ˆ: êµ­ì œ í‘œì¤€í™” ê¸°êµ¬)ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5. ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ ë° ì‘ë‹µ ìƒì„±\n",
    "query = \"ì¹´ë©”ë¼ì—ì„œ ì¡°ë¦¬ê°œ ê°’ì´ ì‚¬ì§„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?\"  # ì˜ˆì œ ì§ˆë¬¸\n",
    "response = qa_chain.run(query)\n",
    "print(\"AI ì‘ë‹µ:\", response)\n",
    "\n",
    "# Step 6. ì „ë¬¸ ìš©ì–´ ì¶”ì¶œ (ì •ê·œ í‘œí˜„ì‹ + GPT í™œìš© ê°€ëŠ¥)\n",
    "def extract_terms(text):\n",
    "    camera_terms = re.findall(r\"\\b(ISO|ì¡°ë¦¬ê°œ|ì…”í„° ìŠ¤í”¼ë“œ|í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤|ì´ˆì  ê±°ë¦¬|ë…¸ì¶œ ë³´ì •|RAW|JPEG|EVF|ê´‘í•™ ì¤Œ)\\b\", text, re.IGNORECASE)\n",
    "    return list(set(camera_terms))  # ì¤‘ë³µ ì œê±°\n",
    "\n",
    "# ì¶”ì¶œëœ ìš©ì–´ í™•ì¸\n",
    "extracted_terms = extract_terms(response)\n",
    "print(\"ì¶”ì¶œëœ ìš©ì–´:\", extracted_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.adapters.openai import convert_openai_messages\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ìš©ì–´: í™”ì´íŠ¸ ë²¨ëŸ°ìŠ¤\n",
      "ì„¤ëª…: í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ëŠ” ì‚¬ì§„ì´ë‚˜ ì˜ìƒì—ì„œ ìƒ‰ìƒì„ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ í‘œí˜„í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ì¹´ë©”ë¼ì˜ ì¤‘ìš”í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ì´ëŠ” íŠ¹íˆ ì¡°ëª…ì´ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì´¬ì˜í•  ë•Œ ë”ìš± ì¤‘ìš”í•´ìš”. ì˜ˆë¥¼ ë“¤ì–´, ì‹¤ë‚´ ì¡°ëª…ì€ ì¢…ì¢… ë…¸ë€ìƒ‰ì´ë‚˜ ì£¼í™©ìƒ‰ ë¹›ì„ ë ê³ , ì•¼ì™¸ì˜ í–‡ë¹›ì€ í‘¸ë¥´ìŠ¤ë¦„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° ìƒí™©ì—ì„œ í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ë¥¼ ì œëŒ€ë¡œ ë§ì¶”ì§€ ì•Šìœ¼ë©´ ì‚¬ì§„ì´ë‚˜ ì˜ìƒì˜ ìƒ‰ìƒì´ ì™œê³¡ë˜ì–´ ë³´ì¼ ìˆ˜ ìˆì£ .\n",
      "\n",
      "í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ëŠ” ì¹´ë©”ë¼ê°€ ë‹¤ì–‘í•œ ì¡°ëª… í™˜ê²½ì—ì„œ ìƒ‰ì˜¨ë„ë¥¼ ê°ì§€í•˜ì—¬ í°ìƒ‰ì´ ë³¸ë˜ì˜ í°ìƒ‰ìœ¼ë¡œ ë³´ì´ë„ë¡ ì¡°ì •í•˜ëŠ” ê³¼ì •ì„ ë§í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ë‹¤ë¥¸ ìƒ‰ìƒë„ ìì—°ìŠ¤ëŸ½ê³  í˜„ì‹¤ì ì¸ ìƒ‰ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ì§„ì‘ê°€ Adam Longì€ ì´ë¥¼ \"í°ìƒ‰ì„ í°ìƒ‰ìœ¼ë¡œ ë³´ì´ë„ë¡ ë§Œë“œëŠ” ë°©ë²•\"ì´ë¼ê³  ì„¤ëª…í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë˜í•œ, í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ë¥¼ ì°½ì˜ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ë¶„ìœ„ê¸°ë‚˜ ëŠë‚Œì„ í‘œí˜„í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë”°ëœ»í•œ ëŠë‚Œì„ ì£¼ê³  ì‹¶ë‹¤ë©´ í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ë¥¼ ì¡°ì •í•˜ì—¬ ì´ë¯¸ì§€ì— ë…¸ë€ìƒ‰ í†¤ì„ ë”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, ì°¨ê°€ìš´ ëŠë‚Œì„ ì›í•œë‹¤ë©´ í‘¸ë¥¸ìƒ‰ í†¤ì„ ê°•ì¡°í•  ìˆ˜ë„ ìˆì£ . ë”°ë¼ì„œ, í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ëŠ” ë‹¨ìˆœíˆ ìƒ‰ì„ ì •í™•íˆ í‘œí˜„í•˜ëŠ” ì—­í• ì„ ë„˜ì–´, ì°½ì˜ì ì¸ ì—°ì¶œì—ë„ ì¤‘ìš”í•œ ë„êµ¬ê°€ ë©ë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7. Tavilyë¥¼ ì´ìš©í•œ ìš©ì–´ë³„ ì›¹ ê²€ìƒ‰ ì‹¤í–‰\n",
    "def search_term(term):\n",
    "    search_results = tavily_client.search(term, search_depth=\"advanced\")[\"results\"]\n",
    "    return \"\\n\".join([result[\"content\"] for result in search_results[:3]])  # ìƒìœ„ 3ê°œ ê²°ê³¼ë¥¼ ë°˜í™˜\n",
    "\n",
    "# Step 8. GPT-4oë¥¼ ì‚¬ìš©í•œ ìš©ì–´ ì„¤ëª… ìƒì„±\n",
    "def explain_term(term, search_data):\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ì¹´ë©”ë¼ ì „ë¬¸ ìš©ì–´ë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ '{term}'ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”:\\n\\n{search_data}\"}\n",
    "    ]\n",
    "    \n",
    "    lc_messages = convert_openai_messages(prompt)\n",
    "    explanation = ChatOpenAI(model=\"gpt-4o\", openai_api_key=os.getenv(\"OPENAI_API_KEY\")).invoke(lc_messages).content\n",
    "    return explanation\n",
    "extracted_terms = [\"í™”ì´íŠ¸ ë²¨ëŸ°ìŠ¤\"]\n",
    "# Step 9. ê° ìš©ì–´ì— ëŒ€í•œ ì„¤ëª… ìƒì„±\n",
    "term_explanations = {}\n",
    "for term in extracted_terms:\n",
    "    search_data = search_term(term)\n",
    "    explanation = explain_term(term, search_data)\n",
    "    term_explanations[term] = explanation\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for term, explanation in term_explanations.items():\n",
    "    print(f\"ğŸ” ìš©ì–´: {term}\\nì„¤ëª…: {explanation}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class InputState(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    question: str\n",
    "    sessionId: int = Field(default=None, description=\"ì—†ìœ¼ë©´ ìƒˆë¡œìš´ session ìƒì„±\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGprojects_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
